# -*- codeing = utf-8 -*-
# @Time : 2020/4/7 17:43
# @Author : liuyi
# @File : test1_v3.py
# @Software : PyCharm
# 中文版改进：1点可以多次通过，边不可以
#          2减少拐弯的算法不再使用论文中的，而是在选择路径时加判断
#                                     选择路径时加判断不可行
# 4.27改进：1起点为4度点
#         2优先选择非桥（把4度点的奖赏调低）
#         3少拐弯，内2度点第二高
import numpy as np
import random

np.set_printoptions(threshold=1e6)  # 设置打印数量的阈值

def setR():
    r = np.array(
        [[-1, -0, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [2, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -0, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -0, -1, -1, -1, -1, -0, -1, -0, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -0, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -0, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -0, -1, -1, -1, -1, -0, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -0, -1, -1, -1, -1, -0,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1,
          -0, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1,
          -1, -0, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0, -1, -0, -1, -1,
          -1, -1, -0, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1,
          -1, -1, -1, -0, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, 2, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -1, -1,
          -0, -1, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1, -0,
          -1, -0, -1, -1, -1, -1, -0, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1, -1,
          -0, -1, -0, -1, -1, -1, -1, -0, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1, -1, -1,
          -1, -0, -1, -1, -1, -1, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1, -1, 2],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0, -1,
          -1, -1, -1, -1, -1, -0, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, 2, -1, 2, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -0, -1, -1, -1, -1, -0, -1, -1, -1, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -0, -1, -1, -1, -1, -1, -1, -0, -1],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, 2, -1, 2],
         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -0, -1, -1, -1, -1, -0, -1],
         #               0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35

         ], dtype=np.float32)

    for i in range(36):
        for j in range(36):
            if r[i, j] == 0:
                r[i, j] = 1
            if r[i, j] == 2:
                r[i, j] = 1

    # r现在-1是不通，1是可以通过
    # 4度点最低，设置为0.5
    r[2, 8] = 0.5
    r[7, 8] = 0.5
    r[9, 8] = 0.5
    r[14, 8] = 0.5
    r[3, 9] = 0.5
    r[8, 9] = 0.5
    r[10, 9] = 0.5
    r[15, 9] = 0.5
    r[7, 13] = 0.5
    r[12, 13] = 0.5
    r[14, 13] = 0.5
    r[19, 13] = 0.5
    r[10, 16] = 0.5
    r[15, 16] = 0.5
    r[17, 16] = 0.5
    r[22, 16] = 0.5
    r[13, 19] = 0.5
    r[18, 19] = 0.5
    r[20, 19] = 0.5
    r[25, 19] = 0.5
    r[16, 22] = 0.5
    r[21, 22] = 0.5
    r[23, 22] = 0.5
    r[28, 22] = 0.5
    r[20, 26] = 0.5
    r[25, 26] = 0.5
    r[27, 26] = 0.5
    r[32, 26] = 0.5
    r[21, 27] = 0.5
    r[26, 27] = 0.5
    r[28, 27] = 0.5
    r[33, 27] = 0.5

    # 内部两度点，第二高
    r[8,7] = 0.8
    #r[8,14] = 0.8
    r[13,7] = 0.8
    #r[13,14] = 0.8
    r[9,10] = 0.8
    #r[9,15] = 0.8
    r[16,10] = 0.8
    #r[16,15] = 0.8
    #r[19,20] = 0.8
    r[19,25] = 0.8
    #r[26,20] = 0.8
    r[26,25] = 0.8
    #r[27,21] = 0.8
    r[27,28] = 0.8
    #r[22,21] = 0.8
    r[22,28] = 0.8

    return r


r = setR()


# print(r)

q = np.zeros([36, 36], dtype=np.float32)

gamma = 0.8

state = random.randint(0, 35)  # 初始状态初始化
for step in range(10000):
    next_state_list = []
    for i in range(36):  # 当前state下的所有动作，收集到next_state_list
        if r[state, i] != -1:
            next_state_list.append(i)
    next_state = next_state_list[random.randint(0, len(next_state_list) - 1)]
    qval = r[state, next_state] + gamma * max(q[next_state])  # 注意qval是一个数值
    q[state, next_state] = qval
    state = next_state

print(r[13])
print(q[13])

# 、、、、、、、、、、、、、、、、、、、、、、、生成路径


def findIndex(value, list):
    for i in range(len(list)):
        if value == list[i]:
            return i + 1
    return False


# for state in firststate:
#
#     print("it's {}st test".format(findIndex(state, firststate)))
#     print("robot start at {}".format(state))
#     q1 = q  # q1去循环变成0矩阵
#
#     while q1.any():
#
#         if not q1[state].any():  # 如果此state全是0,就遍历找一个不全是0的state,肯定能找到
#             for new_state in range(36):
#                 if not q1[new_state].any():
#                     continue
#                 print("from {} jump to {}".format(state, new_state))
#                 state = new_state
#                 break
#         '''
#         if q1[state, state_pre+2]:  # 判断是否可以走直线，与上一个state对比，谁直选谁
#             next_state = state_pre+2
#         elif q1[state, state_pre-2]:
#             next_state = state_pre-2
#         elif q1[state, state_pre+12]:
#             next_state = state_pre+12
#         elif q1[state, state_pre-12]:
#             next_state = state_pre-12
#         else:  # 不能就找最大值
#             q_max = q1[state].max()  # 状态state这一行里的最大值，即回报最大的动作的回报值
#             q_max_action = []
#
#             for action in range(36):  # 找回报最大的动作
#                 if q1[state, action] == q_max:
#                     q_max_action.append(action)
#
#             next_state = q_max_action[random.randint(0, len(q_max_action) - 1)]
#
#         print("the robot goes to " + str(next_state) + '.')
#         q1[state, next_state] = 0
#         q1[next_state, state] = 0
#         state_pre = state
#         state = next_state
#         '''
#
#         q_max = q1[state].max()  # 状态state这一行里的最大值，即回报最大的动作的回报值
#         q_max_action = []
#
#         for action in range(36):  # 找回报最大的动作的下标
#             if q1[state, action] == q_max:
#                 q_max_action.append(action)
#
#         next_state = q_max_action[random.randint(0, len(q_max_action) - 1)]
#         print("the robot goes to " + str(next_state) + '.')
#         q1[state, next_state] = 0
#         q1[next_state, state] = 0
#
#         state = next_state


def findPath(start, q):

    state = start
    print("robot start at {}".format(state))
    while q.any():

        if not q[state].any():  # 如果此state全是0,就遍历找一个不全是0的state,肯定能找到
            for new_state in range(36):
                if not q[new_state].any():
                    continue
                print("from {} jump to {}".format(state, new_state))
                state = new_state
                break

        q_max = q[state].max()  # 状态state这一行里的最大值，即回报最大的动作的回报值
        q_max_action = []

        for action in range(36):  # 找回报最大的动作的下标
            if q[state, action] == q_max:
                q_max_action.append(action)

        next_state = q_max_action[random.randint(0, len(q_max_action) - 1)]
        print("the robot goes to " + str(next_state) + '.')
        q[state, next_state] = 0
        q[next_state, state] = 0

        state = next_state


firststate = [8, 9, 13, 16, 19, 22, 26, 27]
for state in firststate:
    print("it's {}st test".format(findIndex(state, firststate)))
    q1 = q.copy()
    findPath(state, q1)

