path planning + Q-learning

房间例子：
网上的例子，原来的代码有问题，有以下修改：
1、while循环是死循环，加上计数器，或者改为for循环
2、根据Qlearning算法原理，第二层是循环语句不是判断语句
思考：第二层是判断语句也可以得到结果

test1：
对比房间例子只是修改了R矩阵，相当于只是修改了迷宫

test1_v1:
实现英文论文中的算法

test1_v2:
实现中文论文中的算法

test1_v3:
在v2的基础上，修改了两点：
1、可以经过多次点，但是不能经过多次边
2、减少拐弯的算法，修改为在选择时增加判断

总结：
v3版本的第一点是成功的，但是第二点不对，从这里可以看出，当agent处在某一点时选择要不要拐弯，一定是出于全局最优的目的进行选择的，所以要在训练的时候加入约束。英文论文的方法可行。
